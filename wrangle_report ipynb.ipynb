{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA WRANGLING REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to gather WeRateDogs Twitter data and use it to provide enlightening and reliable analysis and visualizations. Although the Twitter archive is fantastic, it only includes the most fundamental tweet data. \"Wow!\"-worthy analysis and visualizations require more collection, assessment, and cleanup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA GATHERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be obtaining all three pieces of information in this step:Â \n",
    "* Udacity provided me with the twitter archive enhanced.csv file to download and submit. After it was downloaded, I read the data into pandas.\n",
    "* The file (image predictions.tsv) was made public through a URL that could be downloaded programmatically.\n",
    "\n",
    "* I queried the Twitter API for each tweet's JSON data using Python's Tweepy package, and I saved each tweet's whole set of JSON data in a file named tweet json.txt. I then retrieved each tweet's minimum retweet and favorite (\"like\") count using the tweet IDs in the WeRateDogs Twitter archive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSESSING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I will visually and programmatically evaluate the three data for concerns with quality and organization.\n",
    "Quality problems\n",
    "\n",
    "##### Twitter archive data: \n",
    "1. The columns (in reply to status id, in reply to user id, retweeted status id, retweeted status timestamp) have an excessive number of missing data.\n",
    "2. rows that have been retweeted\n",
    "\n",
    "3. The expanded urls column has a few missing values.\n",
    "\n",
    "4. The tweet id column should have the string data type.\n",
    "\n",
    "5. The timestamp and retweeted status timestamp fields should be of the datetime data type.\n",
    "\n",
    "6. Fake names are listed in lowercase case in the name column.\n",
    "\n",
    "7. There are html tags in the source column.\n",
    "\n",
    "#### image predictions data:\n",
    "8. The tweet id data type should be a string.\n",
    "\n",
    "9. A few of the names in columns p1, p2, and p3 are small-caps.\n",
    "\n",
    "10. more than one breed predictions.\n",
    "\n",
    "\n",
    "#### tweet data \n",
    "11. The tweet id data type should be string rather than int."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidy issues\n",
    "1.he doggo, floofer, pupper, and puppo columns are data type columns.\n",
    "\n",
    "2.All three datasets may be combined into one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, I cleaned up all of the problems I discovered when assessing. I created a backup of the original data before beginning the cleaning process.\n",
    "I cleaned the following areas:\n",
    "* Remove rows with retweets but no URLs, and remove empty columns.\n",
    "* Consolidated the doggo, floofer, floofer, pupper, and puppo columns into the Dog group column.\n",
    "* Divided twitter archive data clean.rating numerator by twitter archive data clean.rating denominator to get a dog rating column.\n",
    "* Removed tags to extract source.\n",
    "* Removed all fictitious names.\n",
    "* Lowercased columns p1, p2, and p3.\n",
    "* Columns containing incorrect predictions were removed.\n",
    "* By filtering the image with the greatest predicted data, I created a dog breed column.\n",
    "* Removed columns that were no longer required.\n",
    "* Tweet id and date column datatype have been modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle_report.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
